1.kafka的搭建

1.

2.磁盘挂载参数





3.内核参数









**4. 其他要求**

swap分区，不建议直接关闭，建议设置小一点，比如1，这样内存不足时，性能开始出现急剧下降，从而有进一步调优和诊断问题的时间

**5. Kafka版本/配置参数推荐**

**kafka版本：2.8.1**

**jvm配置参数：**

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then export KAFKA_HEAP_OPTS="-Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50  -XX:MaxMetaspaceFreeRatio=80" export JMX_PORT="9999" fi

线上推荐无脑6G，后续观察再适度调整

JMX_PORT推荐写死在kafka-server-start.sh，防止后续端口不一致问题

kafka配置参数

| 参数项                                             | 说明                                                         | 建议项                                                       |
| -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| # listeners=PLAINTEXT://ip:9092                    | 绑定的地址                                                   | 注释掉，监听本机所有9092端口信息                             |
| broker.id=1                                        | 保证broker.id不一致                                          |                                                              |
| num.partitions=9                                   | 每个topic的默认日志分区数                                    | 建议设置为broker个数的倍数，防止数据倾斜                     |
| auto.create.topics.enable=false                    | 自动创建topic配置为broker默认配置，一般不符合业务需求 ，测试集群可以为true |                                                              |
| log.dirs=/data/kakfa/data                          | 线上环境将消息持久化数据保存在指定位置                       |                                                              |
| message.max.bytes=20485760                         | 设置消息的的大小，决定了broker可以接受多大的数据，可以根据业务的不同进行调整 | 设置消息最大                                                 |
| replica.fetch.max.bytes=20485760                   | 指定每个分区的读取请求中使用的字节数，可以根据业务的不同进行调整 |                                                              |
| default.replication.factor=2                       | kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务 | 副本数最小为2，避免单节点故障                                |
| min.insync.replicas=1                              | 决定着每个 topic 能接受的最少 ISR 个数，如果存活 ISR 个数太少，生产消息会报异常。 | 当producer将ack设置为“全部”（或“-1”）时，min.insync.replicas指定了被认为写入成功的最小副本数，如果这个最小值不能满足，那么producer将会引发一个异常（NotEnoughReplicas或NotEnoughReplicasAfterAppend）。当一起使用时，min.insync.replicas和acks允许您强制更大的耐久性保证。一个经典的情况是创建一个复本数为3的topic，将min.insync.replicas设置为2，并且producer使用“all”选项。这将确保如果大多数副本没有写入producer则抛出异常 |
| replica.lag.time.max.ms=10                         | 判断一个副本是否在ISR集合中的标准，如果时间落后大于这个阈值，则表明该副本不在ISR中或者说会从ISR集合中被剔除，否则就表明在ISR集合中或者会被加入到ISR集合中。 | 可根据实际以为适当调大                                       |
| unclean.leader.election.enable=false               |                                                              |                                                              |
| num.io.threads=12                                  | 主要进行磁盘io操作的线程数                                   |                                                              |
| num.network.threads=12                             | 指定用于处理网络请求的线程数                                 |                                                              |
| num.recovery.threads.per.data.dir=4                | 每个数据目录，用于启动时日志恢复和关闭时刷新的线程数。       |                                                              |
| num.replica.fetchers=8                             | 指定用于从源代理复制消息的线程数。增加这个值可以增加代理中I/O操作的并行性 |                                                              |
| log.retention.hours=72                             | 日志删除的时间阈值（小时为单位）                             | 建议设置为72，防止数据过大                                   |
| zookeeper.connect=zk1:2181,zk2:2181,zk3:2181/kafka | 根据需求设置znode存储位置，不可放在zk根目录下                |                                                              |
| zookeeper.connection.timeout.ms=10000              | 与ZK server建立连接的超时时间                                |                                                              |

关于min.insync.replicas=1的个人看法：

首先，Follower副本不提供服务，只是定期地异步拉取Leader副本中的数据而已。既然是异步的，就存在着不可能与 Leader 实时同步的风险。那么Follower副本到底在什么条件下才算与 Leader 同步。

基于这个想法，Kafka 引入了 In-sync Replicas，也就是所谓的 ISR 副本集合。ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的Follower副本就被认为是与 Leader 不同步的。那么，到底什么副本能够进入到 ISR 中呢？

首先要明确的是，Leader 副本天然就在 ISR 中。也就是说，ISR 不只是Follower副本集合，它必然包括 Leader 副本。甚至在某些情况下，ISR 只有 Leader 这一个副本。另外，能够进入到 ISR 的Follower副本要满足一定的条件。至于是什么条件，看看下面这张图。

  ![image-20211230154446446](C:\Users\wb.wangyazhen01\AppData\Roaming\Typora\typora-user-images\image-20211230154446446.png)

图中有 3 个副本：1 个Leader副本和 2 个Follower副本。Leader 副本当前写入了 10 条消息，Follower1 副本同步了其中的 6 条消息，而 Follower2 副本只同步了其中的 3 条消息。对于这 2 个Follower副本，哪个Follower副本与 Leader 不同步？

事实上，这张图中的 2 个 Follower 副本都有可能与 Leader 不同步，但也都有可能与 Leader 同步。也就是说，Kafka 判断 Follower 是否与 Leader 同步，不是看相差的消息数。那同步标准是什么？

这个标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔，默认值是 10 秒(2.5.0更新为30秒)。这就是说，只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。

Follower 副本唯一的工作就是不断地从 Leader 副本拉取消息，然后写入到自己的提交日志中。如果这个同步过程的速度持续慢于 Leader 副本的消息写入速度，那么在 replica.lag.time.max.ms 时间后，此 Follower 副本就会被认为是与 Leader 副本不同步的，因此不能再放入 ISR 中。此时，Kafka 会自动收缩 ISR 集合，将该副本“踢出”ISR。

值得注意的是，倘若该副本后面慢慢地追上了 Leader 的进度，那么它是能够重新被加回 ISR 的。这也表明，ISR 是一个动态调整的集合，而非静态不变的。

话又说回来，为什么要设置为1，不是2，3呢，

既然 ISR 是可以动态调整的，那么自然就可以出现这样的情形：ISR 为空。因为 Leader 副本天然就在 ISR 中，如果 ISR 为空了，**就说明 Leader 副本也“挂掉”了，**Kafka 需要重新选举一个新的 Leader。可是 ISR 是空，此时该怎么选举新 Leader 呢？

Kafka 把所有不在 ISR 中的存活副本都称为非同步副本。通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。

开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。

可以根据实际业务场景决定是否开启 Unclean 领导者选举。不过，我建议不要开启它（虽然官方从0.11.0默认开启），毕竟还可以通过其他的方式来提升高可用性。如果为了高可用性的改善，牺牲了数据一致性，那就非常不值当了。

**总结：**

min.insync.replicas=1，消息至少要被写入到一个副本，才算是真正的写入

case1：当min.insync.replicas=2且acks=all时，如果此时ISR列表只有[1,2],3被踢出ISR列表，只需要保证两个副本同步了，生产者就会收到成功响应.

case2：当min.insync.replicas=2，如果此时ISR列表只有[1],2和3被踢出ISR列表，那么当acks=all时，则不能成功写入；当acks=0或者acks=1可以成功写入数据.

case3：acks=all且min.insync.replicas=2，此时ISR列表为[1,2,3],那么还是会等到所有的同步副本都同步了消息，才会向生产者发送成功响应的ack.因为min.insync.replicas=2只是一个最低限制，即同步副本少于该配置值，则会抛异常，而acks=all，是需要保证所有的ISR列表的副本都同步了才可以发送成功响应。

unclean.leader.election.enable 建议设置为false

优点：保证了数据的一致性。避免了数据的丢失

缺点：丧失了高可用性，可以通过其他方式弥补该高可用

**6. ZooKeeper版本/配置参数推荐**

zookeeper版本：3.4.14. OR 3.5.9？

\# jvm设置2G，开启G1垃圾回收 -Xmx2g -Xms2g -XX:+UseG1GC

**zk配置如下：**

| 参数项                                                       | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| maxClientCnxns=200                                           | 单台客户端机器与单台ZK服务器之间的连接数限制                 |
| tickTime=2000                                                | ZK中的一个时间单元（ms）。ZK中所有时间都是以这个时间单元为基础，进行整数倍配置的 |
| dataDir=/data/zookeeper/zkdata                               | 事务日志输出目录                                             |
| dataLogDir=/data/zookeeper/zklog                             | zk日志目录                                                   |
| clientPort=2182                                              | 客户端连接server的端口，即对外服务端口                       |
| initLimit=10                                                 | Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许Follower在 **initLimit** 时间内完成这个工作。如果ZK集群的数据量确实很大了，Follower在启动的时候，从Leader上同步数据的时间也会相应变长，这种情况下，有必要适当调大这个参数 |
| syncLimit=5                                                  | 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从Follower那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题 |
| server.1=zk1:2881:3881server.2=zk2:2881:3881server.3=zk3:2881:3881 | zk服务地址                                                   |

**7. 部署目录要求**

├── jdk-current -> /home/appops/software/jdk1.8.0_141

├── kafka-current -> /home/appops/software/kafka_2.12-2.8.1/

├── resources

│  ├── jdk-8u141-linux-x64.tar.gz

│  ├── kafka_2.12-2.8.1.tgz

│  └── zookeeper-3.4.14.tar.gz

├── software

│  ├── jdk1.8.0_141

│  ├── kafka_2.12-2.8.1

│  └── zookeeper-3.4.14

└── zookeeper-current -> /home/appops/software/zookeeper-3.4.14/



**Kafka监控覆盖项**

主要包括：主机监控、JVM监控、集群监控三大方面

**一、主机监控**

- 机器负载（Load）
- CPU 使用率（usr，sys，idle，iowait）
- 内存使用率，包括空闲内存（Free Memory）和已使用内存（Used Memory）
- 磁盘 I/O 使用率，包括读使用率和写使用率
- 网络 I/O 使用率
- TCP 连接数
- 打开文件数（watch "lsof | wc -l"）
- inode 使用情况（df -i）

**二、JVM监控**

- Full GC 发生频率和时长。这个指标帮助评估 Full GC 对 Broker 进程的影响。长时间的停顿会令 Broker 端抛出各种超时异常。
- 活跃对象大小。这个指标是你设定堆大小的重要依据，同时它还能帮助你细粒度地调优 JVM 各个代的堆大小。
- 应用线程总数。这个指标帮助你了解 Broker 进程对 CPU 的使用情况。

自 0.9.0.0 版本起，社区将默认的 GC 收集器设置为 G1，而 G1 中的 Full GC 是由单线程执行的，速度非常慢。因此，一定要监控 Broker GC 日志，即以 kafkaServer-gc.log 开头的文件。注意不要出现 Full GC 的字样。一旦发现 Broker 进程频繁 Full GC，可以开启 G1 的 -XX:+PrintAdaptiveSizePolicy 开关，让 JVM 告诉你到底是谁引发了 Full GC。

**三、集群监控**

1. 监控zookeeper进程是否启动，监控zookeeper端口

2. 查看Broker进程是否启动，端口是否建立

3. 查看Broker端关键日志

4. 1. 端服务器日志 server.log
   2. 控制器日志 controller.log
   3. 主题分区状态变更日志 state-change.log

5. 监控Broker端关键线程的运行状态

6. 1. Log Compaction 线程，这类线程是以 kafka-log-cleaner-thread 开头的。就像前面提到的，此线程是做日志 Compaction 的。一旦它挂掉了，所有 Compaction 操作都会中断，但用户对此通常是无感知的。
   2. 副本拉取消息的线程，通常以 ReplicaFetcherThread 开头。这类线程执行 Follower 副本向 Leader 副本拉取消息的逻辑。如果它们挂掉了，系统会表现为对应的 Follower 副本不再从 Leader 副本拉取消息，因而 Follower 副本的 Lag 会越来越大。

7. 查看Broker端的关键JMX指标

8. 1. BytesIn/BytesOut：即 Broker 端每秒入站和出站字节数。你要确保这组值不要接近你的网络带宽，否则这通常都表示网卡已被“打满”，很容易出现网络丢包的情形。
   2. NetworkProcessorAvgIdlePercent：即网络线程池线程平均的空闲比例。通常来说，你应该确保这个 JMX 值长期大于 30%。如果小于这个值，就表明你的网络线程池非常繁忙，你需要通过增加网络线程数或将负载转移给其他服务器的方式，来给该 Broker 减负。
   3. RequestHandlerAvgIdlePercent：即 I/O 线程池线程平均的空闲比例。同样地，如果该值长期小于 30%，你需要调整 I/O 线程池的数量，或者减少 Broker 端的负载。
   4. UnderReplicatedPartitions：即未充分备份的分区数。所谓未充分备份，是指并非所有的 Follower 副本都和 Leader 副本保持同步。一旦出现了这种情况，通常都表明该分区有可能会出现数据丢失。因此，这是一个非常重要的 JMX 指标。
   5. ISRShrink/ISRExpand：即 ISR 收缩和扩容的频次指标。如果你的环境中出现 ISR 中副本频繁进出的情形，那么这组值一定是很高的。这时，你要诊断下副本频繁进出 ISR 的原因，并采取适当的措施。
   6. ActiveControllerCount：即当前处于激活状态的控制器的数量。正常情况下，Controller 所在 Broker 上的这个 JMX 指标值应该是 1，其他 Broker 上的这个值是 0。如果你发现存在多台 Broker 上该值都是 1 的情况，一定要赶快处理，处理方式主要是查看网络连通性。这种情况通常表明集群出现了脑裂。脑裂问题是非常严重的分布式故障，Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作的。

**四、监控实践**

**一、主机监控**

主机监控数据基础监控，创建集群时已经配置好

**二、JVM监控**

采集器：gcstat

**三、集群监控**

采集器：zookeeper_ly，采集zk的信息

采集器：tcp，采集kafka端口信息

采集器：log_keyword2，采集错误日志信息

-f "/home/appops/kafka-current/logs/server.log" -k "ERROR|FATAL"

-f "/home/appops/kafka-current/logs/controller.log" -k "ERROR|FATAL"

-f "/home/appops/kafka-current/logs/state-change.log" -k "ERROR|FATAL"

-f "/home/appops/kafka-current/logs/kafkaServer-gc.log.0.current" -k "ERROR|FATAL"